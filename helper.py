import numpy as np
from pydub import AudioSegment
from music21 import converter, instrument, note, chord, stream
import pickle
from keras.models import Sequential
from keras.layers import LSTM, Dense, Activation, add

#Load the required files and model

pitchnames_path = 'pitchnames.pkl'
net_input_path = 'net_input.pkl'

with open(pitchnames_path, 'rb') as f:
    pitchnames = pickle.load(f)


with open(net_input_path, 'rb') as f:
    net_input = pickle.load(f)


model = Sequential()
model.add(LSTM(256, input_shape=(net_input.shape[1], net_input.shape[2]),return_sequences=True))
model.add(LSTM(512, return_sequences=True))
model.add(LSTM(256, return_sequences=False))
model.add(Dense(256, activation='relu'))
model.add(Dense(194))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])
model.load_weights('weights.weights.h5')
#model.summary()


def predict():
    start = np.random.randint(0, len(net_input)-1)
    pattern = net_input[start]

    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))

    prediction_output = []

    # generate 500 notes
    for note_index in range(500):
        prediction_input = np.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input / float(194)

        prediction = model.predict(prediction_input, verbose=0)
        
        index = np.argmax(prediction)
        result = int_to_note[index]
        prediction_output.append(result)
        pattern= np.append(pattern, index)
        pattern = pattern[1:len(pattern)]
        
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
    #pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)

        #pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 0.5
    
    return output_notes


def convert(output_notes):
    # Convert notes to a music21 stream
    midi_stream = stream.Stream(output_notes)

    # Write the stream to a MIDI file
    midi_file = 'output.mid'
    midi_stream.write('midi', fp=midi_file)

    # Convert MIDI to WAV using pydub (ensure ffmpeg is installed)
    audio_file = 'MusicGenerator\output.wav'
    sound = AudioSegment.from_file(midi_file, format="mid")
    sound.export(audio_file, format="wav")